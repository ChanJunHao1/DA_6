# Importing required Libraries(Task 3)
import requests
import scrapy
from scrapy import Request

url = 'https://brickset.com/sets/year-2003'
# Performs a get request (Task 5i)
r = requests.get(url)
# uncomment below if you want the whole webpage to be dumped out in text(To show the Get Request being shown)
print(r.text)

# Code below gives the "OK" return status(Task 5ii)
print("Status code:")
print("\t *", r.status_code)

# To modify the headers user-agent to display Mobile(Task 5iv)

headers = {
    'User-Agent': 'Mobile'
}

# For Testing to show if User Agent was changed to mobile
# url2 = 'http://httpbin.org/headers'
# rh = requests.get(url2, headers=headers)
# print(rh.text)

# Code below Displays the Website header, headers=headers changes user-agent to mobile(Task 5 iii)
h = requests.get(url, headers=headers)
print("Header:")
print("**********")
# To get line by line
for x in h.headers:
    print("\t ", x, ":", h.headers[x])
print("**********")

# Displays reference webpage
# scrapy runspider PenTest.py -o results.json -t json
# Command above is used in terminal to save output to a JSON file

class BrickSetSpider(scrapy.Spider):
    name = "brickset_spider"
    start_urls = ['https://brickset.com/sets/year-2003']
# To Bypass Anti-Scraping Measures
    def start_requests(self):
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'}
        for url in self.start_urls:
            yield Request(url, headers=headers)

    def parse(self, response):
        SET_SELECTOR = '.set'
        for brickset in response.css(SET_SELECTOR):
            NAME_SELECTOR = 'h1 ::text'
            PIECES_SELECTOR = './/dl[dt/text() = "Pieces"]/dd/a/text()'
            MINIFIGS_SELECTOR = './/dl[dt/text() = "Minifigs"]/dd[2]/a/text()'
            IMAGE_SELECTOR = 'img ::attr(src)'
            yield {
                'name': brickset.css(NAME_SELECTOR).extract_first(),
                'pieces': brickset.xpath(PIECES_SELECTOR).extract_first(),
                'minifigs': brickset.xpath(MINIFIGS_SELECTOR).extract_first(),
                'image': brickset.css(IMAGE_SELECTOR).extract_first(),
            }

        NEXT_PAGE_SELECTOR = '.next a ::attr(href)'
        next_page = response.css(NEXT_PAGE_SELECTOR).extract_first()
        if next_page:
            yield scrapy.Request(
                response.urljoin(next_page),
                callback=self.parse
            )

